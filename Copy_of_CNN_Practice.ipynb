{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VicentePina7210/DataMiningCleaningExercise/blob/main/Copy_of_CNN_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_L-DXY4L2D8E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "5c3e5a90-b7cf-4903-f12a-eeb004a6d302"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Only a single TORCH_LIBRARY can be used to register the namespace triton; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /dev/null:2623; latest registration was registered at /dev/null:2623",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-31abc8079c23>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2621\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompiler\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcompiler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2623\u001b[0;31m     \u001b[0;32mclass\u001b[0m \u001b[0m_TritonLibrary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2624\u001b[0m         \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"triton\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DEF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m         \u001b[0mops_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_Dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_Tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Callable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m_TritonLibrary\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2623\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0m_TritonLibrary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2624\u001b[0;31m         \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"triton\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DEF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2625\u001b[0m         \u001b[0mops_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_Dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_Tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Callable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/library.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ns, kind, dispatch_key)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         self.m: Optional[Any] = torch._C._dispatch_library(\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdispatch_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Only a single TORCH_LIBRARY can be used to register the namespace triton; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /dev/null:2623; latest registration was registered at /dev/null:2623"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import requests\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "from scipy import ndimage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az_Ym5Ea4zpX"
      },
      "source": [
        "## Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RE5NlDu2TMk"
      },
      "outputs": [],
      "source": [
        "# Load image from url\n",
        "img_url = \"https://img.jamesedition.com/listing_images/2024/12/25/12/13/27/23579aec-8f1b-4361-b43c-417a08b91137/je/1100xxs.jpg\"\n",
        "res = requests.get(img_url)\n",
        "img_arr = np.array(Image.open(BytesIO(res.content)))\n",
        "img_arr = img_arr[:,:,0] / 255.0\n",
        "plt.imshow(img_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofM6fK0U3OsK"
      },
      "outputs": [],
      "source": [
        "# Downsample image\n",
        "new_img = ndimage.zoom(img_arr, 0.25)\n",
        "plt.imshow(new_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YY9ol6ZT2ogi"
      },
      "outputs": [],
      "source": [
        "# Convolve image\n",
        "kernel = np.array([\n",
        "    [0, -2, -1],\n",
        "    [2, 0, -2],\n",
        "    [1, 2, 0]\n",
        "])\n",
        "plt.imshow(ndimage.convolve(new_img, kernel))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv2UZkrf42bi"
      },
      "source": [
        "## Convolutional Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N15Z4Xo5Y39"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmRGuq785aRj"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset with transformations\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainset = torch.utils.data.Subset(trainset, range(1000))\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testset = torch.utils.data.Subset(testset, range(1000))\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n745O69c5XDz"
      },
      "outputs": [],
      "source": [
        "# Define CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 5, padding=2)  # Conv layer (input: 1 channel, output: 16, 3x3 kernel)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 5, padding=2) # Second conv layer (16 -> 32 filters)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 5, padding=2) #          Second conv layer (16 -> 32 filters)\n",
        "        self.fc1 = nn.Linear(32 * 7 * 7, 128)  # Fully connected layer\n",
        "        self.fc2 = nn.Linear(128, 10)  # Output layer (10 classes for digits)\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # 2x2 max pooling\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))  # Conv -> ReLU -> Pool\n",
        "        x = self.pool(self.relu(self.conv2(x)))  # Conv -> ReLU -> Pool\n",
        "        x = x.view(-1, 32 * 7 * 7)  # Flatten for FC layers\n",
        "        x = self.relu(self.fc1(x))  # Fully connected layer -> ReLU\n",
        "        x = self.fc2(x)  # Output layer\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYWp7qqP6-cc"
      },
      "outputs": [],
      "source": [
        "# Initialize model, loss function, and optimizer\n",
        "model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBQKMgKn5eeo"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "for epoch in range(5):  # Train for 5 epochs\n",
        "    for images, labels in trainloader:\n",
        "        optimizer.zero_grad()  # Reset gradients\n",
        "        outputs = model(images)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
        "\n",
        "# Testing loop\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6gIfZYw6Hur"
      },
      "outputs": [],
      "source": [
        "# Get the weights of the first convolutional layer\n",
        "filters = model.conv1.weight.data  # Shape: (16, 1, 3, 3) -> 16 filters of size 3x3\n",
        "\n",
        "# Convert to numpy for visualization\n",
        "filters = filters.squeeze().numpy()  # Remove the singleton dimension\n",
        "\n",
        "# Plot the filters\n",
        "fig, axes = plt.subplots(4, 4, figsize=(6, 6))  # 4x4 grid for 16 filters\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(filters[i], cmap=\"gray\")  # Show filter as grayscale\n",
        "    ax.axis(\"off\")  # Remove axis ticks\n",
        "\n",
        "plt.suptitle(\"Learned Filters in First Conv Layer\", fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "ZCDESlOh7shO",
        "outputId": "58e62f32-585a-48e2-90cb-8bd2f18fcb83"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Only a single TORCH_LIBRARY can be used to register the namespace triton; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /dev/null:2623; latest registration was registered at /dev/null:2623",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-70cba5d93c30>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Function to extract and visualize feature maps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvisualize_feature_maps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2621\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompiler\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcompiler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2623\u001b[0;31m     \u001b[0;32mclass\u001b[0m \u001b[0m_TritonLibrary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2624\u001b[0m         \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"triton\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DEF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m         \u001b[0mops_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_Dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_Tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Callable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m_TritonLibrary\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2623\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0m_TritonLibrary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2624\u001b[0;31m         \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"triton\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DEF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2625\u001b[0m         \u001b[0mops_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_Dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_Tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Callable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/library.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ns, kind, dispatch_key)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         self.m: Optional[Any] = torch._C._dispatch_library(\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdispatch_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Only a single TORCH_LIBRARY can be used to register the namespace triton; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /dev/null:2623; latest registration was registered at /dev/null:2623"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to extract and visualize feature maps\n",
        "def visualize_feature_maps(model, image):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    layers = [model.conv1, model.conv2]  # Choose layers to visualize\n",
        "\n",
        "    activations = []\n",
        "    x = image.unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Forward pass through selected layers\n",
        "    for layer in layers:\n",
        "        x = layer(x)\n",
        "        x = torch.relu(x)  # Apply ReLU activation\n",
        "        activations.append(x)\n",
        "\n",
        "    # Plot original image\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(image.squeeze().numpy(), cmap=\"gray\")\n",
        "    plt.title(\"Original Input Image\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    # Plot feature maps for each layer\n",
        "    for i, activation in enumerate(activations):\n",
        "        num_filters = activation.shape[1]  # Number of channels (filters)\n",
        "        fig, axes = plt.subplots(1, num_filters, figsize=(num_filters * 2, 2))\n",
        "\n",
        "        if num_filters == 1:\n",
        "            axes = [axes]  # Ensure axes is iterable\n",
        "\n",
        "        for j in range(num_filters):\n",
        "            axes[j].imshow(activation[0, j].detach().numpy(), cmap=\"gray\")\n",
        "            axes[j].axis(\"off\")\n",
        "\n",
        "        plt.suptitle(f\"Feature Maps After Layer {i+1}\")\n",
        "        plt.show()\n",
        "\n",
        "# Get a sample image from test loader\n",
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "sample_image = images[0]  # Take first image\n",
        "\n",
        "# Visualize feature maps\n",
        "visualize_feature_maps(model, sample_image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgYXJyNG6pXC"
      },
      "source": [
        "## Questions\n",
        "1. How does changing the kernel size in the convolutional layers affect accuracy?\n",
        "By increasing the size of the kernel to 5 and padding to 2, I was able to get better test accuracy. On the other hand once I increased it to a higher number like 8 with padding 4, I saw a decrease in accuracy. The increase was likely letting the model become more complex, but increasing it too much could have led the model to underfit and not really pickup any patterns.\n",
        "\n",
        "2. What happens if you increase or decrease the number of filters in each convolutional layer?\n",
        "By increasing the number of filters in the layersit made the accuracy improve but the code took some more time to run.\n",
        "By decreasing, the code ran faster but lost some performance.\n",
        "\n",
        "3. What is the effect of adding an extra convolutional layer?\n",
        "The model performs better with an extra layer. This is likely becuase the model is able to become more complex.\n",
        "\n",
        "4. What happens if you remove the pooling layers?\n",
        "Removing the pooling layer gave mixed results each time. It seems as if it makes the model more prone to overfitting. sometimes I got high accuracy and other times I got a relatively low accuracy.\n",
        "\n",
        "5. How do you interpret the learned filter patterns? Are they understandable? Why or why not?\n",
        "For the most part they are interpretable,  they mostly make sense and give an overall generalization of the main features of the number and they key points of the number. They all capture the defifining elements of the number. However a few done seem to capture enough\n",
        "\n",
        "6. Do you think the learned filters could be more understandable for a different dataset?\n",
        "I would say yes, depending on the number and the image used it could come close. The font could be different and the CNN would compensate for that with the filters.\n",
        "\n",
        "\n",
        "7. Why does increasing the kernel size impact the receptive field of a convolutional layer?\n",
        "Increasing the size of the kernel directly effects what the CNN sees. Increasing the size of the kernel would allow the CNN to see more and therefore the netowrk would be able to gain a better general understanding."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}